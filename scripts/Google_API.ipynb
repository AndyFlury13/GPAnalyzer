{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Photos API - Download images from Google Photos using Python\n",
    "\n",
    "Using the Google Photos REST API you can download, upload and modify images stored in Google Photos.\n",
    "\n",
    "The following steps describe how to set up a simple project that lets you use Python to download images from Google Photos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture capt \n",
    "#saves the output to variable capt, to print output capt.stdout, capt.stderr\n",
    "!pip install -r \"requirements.txt\"\n",
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/andyflury/opt/anaconda3/bin/python\n",
      "/Users/andyflury/opt/anaconda3/bin/pip\n"
     ]
    }
   ],
   "source": [
    "!which python\n",
    "!which pip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Use the Google Photo Library API for the first time:\n",
    "\n",
    "The following section shows how to use OAuth Credentials for authentication with the Google Library API. The code section below covers the following steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Create a service for the first time:\n",
    "\n",
    "    1. Initialize GooglePhotosApi `google_photos_api = GooglePhotosApi()`\n",
    "\n",
    "    2. Create Service using the `client_secret.json` file: `service = google_photos_api.create_service()`\n",
    "        \n",
    "        \n",
    "       <b>Calling the API for the first time:</b>\n",
    "       1. Google will ask you if you want to grant the App the required permissions you defined with the scope:\n",
    "       ![](read_me_img/sign_in_google_acc.png)\n",
    "       2. Since its just a test app at the moment, Google will make you aware of that > Click on \"Continue\"\n",
    "       3. Once you granted the app the required permissions, you will see a \"token_......pickle\" file created in the folder \"credentials\". This token file will be used for future calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "from google_auth_oauthlib.flow import Flow, InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from google.auth.transport.requests import Request\n",
    "import requests\n",
    "\n",
    "class GooglePhotosApi:\n",
    "    def __init__(self,\n",
    "                 api_name = 'photoslibrary',\n",
    "                 client_secret_file= r'./credentials/client_secret.json',\n",
    "                 api_version = 'v1',\n",
    "                 scopes = ['https://www.googleapis.com/auth/photoslibrary']):\n",
    "        '''\n",
    "        Args:\n",
    "            client_secret_file: string, location where the requested credentials are saved\n",
    "            api_version: string, the version of the service\n",
    "            api_name: string, name of the api e.g.\"docs\",\"photoslibrary\",...\n",
    "            api_version: version of the api\n",
    "\n",
    "        Return:\n",
    "            service:\n",
    "        '''\n",
    "\n",
    "        self.api_name = api_name\n",
    "        self.client_secret_file = client_secret_file\n",
    "        self.api_version = api_version\n",
    "        self.scopes = scopes\n",
    "        self.cred_pickle_file = f'./credentials/token_{self.api_name}_{self.api_version}.pickle'\n",
    "\n",
    "        self.cred = None\n",
    "\n",
    "    def run_local_server(self):\n",
    "        # is checking if there is already a pickle file with relevant credentials\n",
    "        if os.path.exists(self.cred_pickle_file):\n",
    "            with open(self.cred_pickle_file, 'rb') as token:\n",
    "                self.cred = pickle.load(token)\n",
    "\n",
    "        # if there is no pickle file with stored credentials, create one using google_auth_oauthlib.flow\n",
    "        if not self.cred or not self.cred.valid:\n",
    "            if self.cred and self.cred.expired and self.cred.refresh_token:\n",
    "                self.cred.refresh(Request())\n",
    "            else:\n",
    "                flow = InstalledAppFlow.from_client_secrets_file(self.client_secret_file, self.scopes)\n",
    "                self.cred = flow.run_local_server()\n",
    "\n",
    "            with open(self.cred_pickle_file, 'wb') as token:\n",
    "                pickle.dump(self.cred, token)\n",
    "        \n",
    "        return self.cred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize photos api and create service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_PHOTOS_API = GooglePhotosApi()\n",
    "CREDS = GOOGLE_PHOTOS_API.run_local_server()\n",
    "PHOTOS_HEADERS = {\n",
    "    'content-type': 'application/json',\n",
    "    'Authorization': 'Bearer {}'.format(CREDS.token)\n",
    "}\n",
    "\n",
    "def init_gp_server():\n",
    "    global GOOGLE_PHOTOS_API, CREDS, PHOTO_HEADERS\n",
    "    GOOGLE_PHOTOS_API = GooglePhotosApi()\n",
    "    CREDS = GOOGLE_PHOTOS_API.run_local_server()\n",
    "    PHOTOS_HEADERS = {\n",
    "        'content-type': 'application/json',\n",
    "        'Authorization': 'Bearer {}'.format(CREDS.token)\n",
    "    }\n",
    "init_gp_server()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use pythons requests module and the token file to retrieve data from Google Photos\n",
    "\n",
    "The functions here\n",
    "1. request media items from Hilledwight shared album and store the item IDs in picIds.txt\n",
    "2. request media items from all my photos organized by month and store the items IDs respective txt files in the idFiles directory\n",
    "\n",
    "We're limiting the number of pictures requested by numPics in each function, but in the future we'll remove numPics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "GET_LIBRARIES_URL = 'https://photoslibrary.googleapis.com/v1/albums'\n",
    "MEDIA_ITEMS_URL = 'https://photoslibrary.googleapis.com/v1/mediaItems:search'\n",
    "\n",
    "MAX_NUM_PICS = 5200000000\n",
    "MONTHS = [\n",
    "    {'month': 8, 'year':2021, 'name':'August'}, \n",
    "    {'month': 9, 'year':2021, 'name': 'September'}, \n",
    "    {'month': 10, 'year':2021, 'name': 'October'}, \n",
    "    {'month': 11, 'year':2021, 'name': 'November'}, \n",
    "    {'month': 12, 'year':2021, 'name': 'December'}, \n",
    "    {'month': 1, 'year':2022, 'name': 'January'}, \n",
    "    {'month': 2, 'year':2022, 'name': 'February'}, \n",
    "    {'month': 3, 'year':2022, 'name': 'March'},\n",
    "    {'month': 4, 'year':2022, 'name': 'April'}, \n",
    "    {'month': 5, 'year':2022, 'name': 'May'}, \n",
    "    {'month': 6, 'year':2022, 'name': 'June'}, \n",
    "]\n",
    "\n",
    "CATEGORIES = [\n",
    "    ['ANIMALS,PETS','ANIMALS'],\n",
    "    ['FASHION'],\n",
    "    ['LANDMARKS'],\n",
    "    ['ARTS'],\n",
    "    ['FLOWERS','GARDENS','LANDSCAPES', 'NATURE'],\n",
    "    ['BIRTHDAYS'],\n",
    "    ['FOOD'],\n",
    "    ['NIGHT'],\n",
    "    ['SELFIES'],\n",
    "    ['CITYSCAPES', 'HOUSES', 'CITYSCAPES'],\n",
    "    ['PEOPLE'],\n",
    "    ['SPORT'],\n",
    "    ['HOLIDAYS'],\n",
    "    ['CRAFTS'],\n",
    "    ['PERFORMANCES'],\n",
    "    ['TRAVEL'],\n",
    "    ['RECEIPTS','WEDDINGS','WHITEBOARDS','SCREENSHOTS','UTILITY','DOCUMENTS', 'MISC']\n",
    "]\n",
    "\n",
    "def writeToFile(f, mediaItems):\n",
    "    for item in mediaItems:\n",
    "        try:\n",
    "            f.write('%s\\n' %item['id'])\n",
    "        except:\n",
    "            print('!!!! WARNING: Write error !!!!')\n",
    "\n",
    "def get_hd_people_pics():\n",
    "    print('Downloading HD pics...')\n",
    "    try:\n",
    "        res = requests.request(\"GET\", GET_LIBRARIES_URL, headers=PHOTOS_HEADERS)\n",
    "        albumID = res.json()['albums'][1]['id']\n",
    "    except:\n",
    "        print('!!!! WARNING: Library request error !!!!') \n",
    "        print(res)\n",
    "        return\n",
    "    \n",
    "    payload = {\n",
    "      \"albumId\": albumID,\n",
    "      \"pageSize\": \"25\"\n",
    "    }\n",
    "    res = requests.request(\"POST\", MEDIA_ITEMS_URL,  data=json.dumps(payload), headers=PHOTOS_HEADERS)\n",
    "    res = res.json()\n",
    "    if 'error' in res:\n",
    "        print('!!!! WARNING: Library request error !!!!')\n",
    "        print(res)\n",
    "        return\n",
    "    numPics = 0\n",
    "    with open('idFiles/picIDs.txt', 'w+') as f:\n",
    "        while 'nextPageToken' in res and numPics < MAX_NUM_PICS:\n",
    "            if 'mediaItems' in res:\n",
    "                writeToFile(f, res['mediaItems'])\n",
    "            numPics += len(res['mediaItems'])\n",
    "            payload = {\n",
    "              \"albumId\": albumID,\n",
    "              \"pageSize\": \"25\",\n",
    "              \"pageToken\": res['nextPageToken'],\n",
    "            }\n",
    "            res = requests.request(\"POST\", MEDIA_ITEMS_URL,  data=json.dumps(payload), headers=PHOTOS_HEADERS)\n",
    "            res = res.json()\n",
    "            if 'error' in res:\n",
    "                print('!!!! WARNING: Library request error !!!!')\n",
    "                print(res)\n",
    "                return\n",
    "    f.close()\n",
    "    print('Download complete!')\n",
    "    return numPics\n",
    "\n",
    "def get_month_pics(monthEntry):\n",
    "    payload = {\n",
    "      \"filters\": {\n",
    "        \"dateFilter\": {\n",
    "          \"dates\": [\n",
    "            {\n",
    "              \"month\": monthEntry['month'],\n",
    "              \"year\": monthEntry['year']\n",
    "            }\n",
    "           ]\n",
    "            }\n",
    "          },\n",
    "        \"pageSize\": \"25\"\n",
    "    }\n",
    "    \n",
    "    res = requests.request(\"POST\", MEDIA_ITEMS_URL,  data=json.dumps(payload), headers=PHOTOS_HEADERS)\n",
    "    res = res.json()\n",
    "    if 'error' in res:\n",
    "        print('!!!! WARNING: Library request error !!!!')\n",
    "        print(res)\n",
    "        return\n",
    "    numPics = 0\n",
    "        \n",
    "    with open('idFiles/months/'+monthEntry['name']+'PicIDs.txt', 'w+') as f:\n",
    "        while 'nextPageToken' in res and numPics < MAX_NUM_PICS:\n",
    "            if 'mediaItems' in res:\n",
    "                writeToFile(f, res['mediaItems'])\n",
    "            payload = {\n",
    "              \"filters\": {\n",
    "                \"dateFilter\": {\n",
    "                  \"dates\": [\n",
    "                    {\n",
    "                      \"month\": monthEntry['month'],\n",
    "                      \"year\": monthEntry['year']\n",
    "                    }\n",
    "                   ]\n",
    "                }\n",
    "              },\n",
    "              \"pageSize\": \"25\",\n",
    "              \"pageToken\": res['nextPageToken']\n",
    "            }\n",
    "            res = requests.request(\"POST\", MEDIA_ITEMS_URL,  data=json.dumps(payload), headers=PHOTOS_HEADERS)\n",
    "            res = res.json()\n",
    "            if 'error' in res:\n",
    "                print('!!!! WARNING: Library request error !!!!')\n",
    "                print(res)\n",
    "                return\n",
    "            numPics += len(res['mediaItems'])\n",
    "    f.close()\n",
    "    return numPics\n",
    "\n",
    "def get_all_month_pics():\n",
    "    print('Downloading pics with monthly filter...')\n",
    "    for monthEntry in MONTHS:\n",
    "        get_month_pics(monthEntry)\n",
    "    print('Download complete!')\n",
    "        \n",
    "        \n",
    "def get_category_pics(category):\n",
    "    categoryLabel = category[0]\n",
    "    if len(category)>1:\n",
    "        categoryLabel = category[-1]\n",
    "        category = category[0:len(category)-1]\n",
    "    payload = {\n",
    "      \"filters\": {\n",
    "        \"contentFilter\": {\n",
    "          \"includedContentCategories\": category\n",
    "        }\n",
    "      },\n",
    "      \"pageSize\": \"25\"\n",
    "    }\n",
    "    \n",
    "    res = requests.request(\"POST\", MEDIA_ITEMS_URL,  data=json.dumps(payload), headers=PHOTOS_HEADERS)\n",
    "    res = res.json()\n",
    "    if 'error' in res:\n",
    "        print('!!!! WARNING: Library request error !!!!')\n",
    "        print(res)\n",
    "        return\n",
    "    numPics = 0\n",
    "    with open('idFiles/categories/'+categoryLabel+'PicIDs.txt', 'w+') as f:\n",
    "        while 'nextPageToken' in res and numPics < MAX_NUM_PICS:\n",
    "            if 'mediaItems' in res:\n",
    "                writeToFile(f, res['mediaItems'])\n",
    "            payload = {\n",
    "              \"filters\": {\n",
    "                \"contentFilter\": {\n",
    "                  \"includedContentCategories\": category\n",
    "                }\n",
    "              },\n",
    "              \"pageSize\": \"25\",\n",
    "              \"pageToken\": res['nextPageToken']\n",
    "            }\n",
    "            \n",
    "            res = requests.request(\"POST\", MEDIA_ITEMS_URL,  data=json.dumps(payload), headers=PHOTOS_HEADERS)\n",
    "            res = res.json()\n",
    "            if 'error' in res:\n",
    "                print('!!!! WARNING: Library request error !!!!')\n",
    "                print(res)\n",
    "                return\n",
    "            numPics += len(res['mediaItems'])\n",
    "    f.close()\n",
    "    return numPics\n",
    "    \n",
    "def get_all_category_pics():\n",
    "    print('Downloading pics with category filter...')\n",
    "    for category in CATEGORIES:\n",
    "        get_category_pics(category)\n",
    "    print('Download complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "testID='AMyo5r0lZANxOJrBM7XH887PZfWTyK_x6LgX_n51XULlarUSqYiLm8g-L4xEEsX08zcy2HKmEDI8iMp09XTA0RCHYCR0MfxB7w'\n",
    "res = requestIMG(testID)\n",
    "downloadIMG(res['baseUrl'], 'testIMG.jpg')\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CompreFace Request\n",
    "\n",
    "To request the CompreFace api, we need to first request the media item from the Google Photos API, which validates the baseUrl for 60 minutes, then download the image and then send this file in our request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Request image with imgID\n",
    "    We can only download the image from baseURL if we have requested\n",
    "    the url from GP API and make our download request within 60 minutes\n",
    "\"\"\"\n",
    "\n",
    "def requestIMG(imgID):\n",
    "    url = 'https://photoslibrary.googleapis.com/v1/mediaItems/'+imgID\n",
    "    headers = {\n",
    "        'content-type': 'application/json',\n",
    "        'Authorization': 'Bearer {}'.format(CREDS.token)\n",
    "    }\n",
    "    res = requests.request(\"GET\", url, headers=headers)\n",
    "    return res.json()\n",
    "\n",
    "\"\"\"\n",
    "    Download image and place in WD\n",
    "\"\"\"\n",
    "def downloadIMG(url, file_name='imgToRecognize.jpg'):\n",
    "    downloadResponse = requests.get(url)\n",
    "    destination_folder = './downloads/'\n",
    "    with open(os.path.join(destination_folder, file_name), 'wb') as f:\n",
    "        f.write(downloadResponse.content)\n",
    "        f.close()\n",
    "\n",
    "\"\"\"\n",
    "    Request the CompreFace API to recognize faces\n",
    "\"\"\"\n",
    "def recognizeFace(url):\n",
    "    downloadIMG(url)\n",
    "    headers = {\n",
    "        'x-api-key': '0bedc62b-b2a4-4eb2-8efd-b62cc275e23c',\n",
    "    }\n",
    "\n",
    "    files = {\n",
    "        'file': open('./downloads/imgToRecognize.jpg', 'rb'),\n",
    "    }\n",
    "\n",
    "    res = requests.post('http://localhost:8000/api/v1/recognition/recognize?face_plugins=landmarks, gender, age', headers=headers, files=files)\n",
    "    return res.json()\n",
    "\n",
    "PHONES_TO_PERSON = {\n",
    "    'BE2026': 'chimu',\n",
    "    'SM-G970U':'shirleyWhirley',\n",
    "    'iPhone 11': 'jiusus',\n",
    "    'Pixel 3': 'bugBoy',\n",
    "    'Pixel 5a': 'bugBoy',\n",
    "    'iPhone 12': 'girlBoss',\n",
    "    'iPhone X': 'me',\n",
    "    'iPhone 8': 'girlBoss',\n",
    "    'moto g(7) plus': 'chimu',\n",
    "    'A6013': 'yuppie',\n",
    "    'ONEPLUS A6013': 'yuppie',\n",
    "    'foodie': 'jiusus',\n",
    "    'iphone 7': 'dumbestKid',\n",
    "    'Canon EOS R6': 'other'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build matrices\n",
    "\n",
    "Build the takerSubject, picturedWith, and month-based matrices. The values of each cell is a string of comma separated item IDs which we'll hopefully use to request pictures in our final visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ya29.A0AVA9y1vUC9dKZfMcozETFpfzXw4JnNYRvrwgR4uRf70VDE4MpbcnLRAcs2n58cQvpKf99TnsA-XuL-ws-iILrw-I7zOM0K4zbWAncnKS_xmZ5NjcyCKN7Rw4zKzFArdG33pEK6OIBEP42jMPdVTmLY3Xsom8AFcaCgYKATASATASFQE65dr8sik9CSNUC6CGlWpdqmWwaw0166\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(print(CREDS.token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "NAMES = ['me', 'girlBoss', 'bugBoy', 'jiusus', 'chimu', 'shirleyWhirley', 'yuppie', 'dumbestKid', 'emily', 'other']\n",
    "RECOGNITION_THRESHOLD = .8 ## The similarity above which we allow a recognition\n",
    "\n",
    "def getPictureTaker(imgID):\n",
    "    GPRes = requestIMG(imgID) \n",
    "    try:\n",
    "        mediaMetadata = GPRes['mediaMetadata']\n",
    "    except:\n",
    "        print('!!!! WARNING: GPRes error while trying to get picture taker')\n",
    "        print(GPRes)\n",
    "        errorCode = GPRes['error']['code']\n",
    "        if errorCode == 401:\n",
    "            init_gp_server()\n",
    "            GPRes = requestIMG(imgID)\n",
    "            mediaMetadata = GPRes['mediaMetadata']\n",
    "        elif errorCode == 429:\n",
    "            print('GP quota reached. Writing matrices to file...')\n",
    "            return '429', ''\n",
    "            \n",
    "        else:\n",
    "            return 'video', ''\n",
    "    if 'photo' in mediaMetadata:\n",
    "        photo = mediaMetadata['photo']\n",
    "        if 'cameraModel' in photo:\n",
    "            phoneType = photo['cameraModel']\n",
    "            try:\n",
    "                return PHONES_TO_PERSON[phoneType], GPRes['baseUrl']\n",
    "            except:\n",
    "                print('!!!! WARNING: Unrecognized camera')\n",
    "                print(GPRes)\n",
    "                downloadIMG(GPRes['baseUrl'], 'pictureTakerErr.jpg')\n",
    "                return 'video', ''\n",
    "        else:\n",
    "            return 'jiusus', GPRes['baseUrl']\n",
    "    else:\n",
    "        return 'video', ''\n",
    "\n",
    "\"\"\"\n",
    "    Identify the faces in an image. Given the picture taker, increment the edge between\n",
    "    pictureTaker and the face in the image.\n",
    "    \n",
    "\"\"\"\n",
    "def processRecognition(res, pictureTaker, matrices, imgID, month=None):\n",
    "    picturedWithMatrix, takerSubjectMatrix, subjectCounts, pictureOfSubjectByMonth = matrices\n",
    "    if 'result' not in res:\n",
    "        return\n",
    "    results = res['result']\n",
    "    subjects = []\n",
    "    for result in results: ## Iterates through every face in picture\n",
    "        possibleSubjects = result['subjects']\n",
    "        if len(possibleSubjects) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            if possibleSubjects[0]['similarity'] < RECOGNITION_THRESHOLD:\n",
    "                continue\n",
    "            else:\n",
    "                photoSubject = possibleSubjects[0]['subject']\n",
    "                if photoSubject not in NAMES:\n",
    "                    photoSubject = 'other'\n",
    "                if month is None:\n",
    "                    subjects.append(photoSubject)\n",
    "                    takerSubjectMatrix.at[pictureTaker, photoSubject] += imgID+','\n",
    "                    subjectCounts[photoSubject]['asSubject'] += 1\n",
    "                    subjectCounts[pictureTaker]['asPhototaker'] += 1\n",
    "                else:\n",
    "                    pictureOfSubjectByMonth.at[photoSubject, month] += imgID+','\n",
    "    subject_i, subject_j = 0, 1\n",
    "    if month is None:\n",
    "        while subject_i < len(subjects):\n",
    "            firstSubject = subjects[subject_i]\n",
    "            while subject_j < len(subjects):\n",
    "                secondSubject = subjects[subject_j]\n",
    "                picturedWithMatrix.at[firstSubject, secondSubject] += imgID+','\n",
    "                picturedWithMatrix.at[secondSubject, firstSubject] += imgID+',' ## Make matrix symmetric for convenience\n",
    "                subject_j += 1\n",
    "            subject_i += 1\n",
    "            subject_j = subject_i + 1\n",
    "\n",
    "def createSubjectMatrices():\n",
    "    picturedWithMatrix, takerSubjectMatrix = getMatrix('picturedWith'), getMatrix('takerSubject')\n",
    "    overallStats = getOverallStatsJSON()\n",
    "    print('Building subject-taker and photographed with matrices...')\n",
    "    idFile = open('idFiles/picIDs.txt', 'r')\n",
    "    start = int(getStart(\"subject\"))\n",
    "    ids = idFile.readlines()[start:]\n",
    "    \n",
    "    for entry in enumerate(ids):\n",
    "        imgIDNum, imgID = entry[0]+start, entry[1][:-1]\n",
    "        (pictureTaker, url) = getPictureTaker(imgID) # Cut out the EOL token\n",
    "        if pictureTaker == '429':\n",
    "            writeMatrix(picturedWithMatrix, 'picturedWith')\n",
    "            writeMatrix(takerSubjectMatrix, 'takerSubject')\n",
    "            writeStart(imgIDNum, 'subject')\n",
    "            return\n",
    "        if pictureTaker == 'video':\n",
    "            continue\n",
    "        else:\n",
    "            try:\n",
    "                recognitionRes = recognizeFace(url)\n",
    "                matrices = (picturedWithMatrix, takerSubjectMatrix, overallStats, None)\n",
    "                processRecognition(recognitionRes, pictureTaker, matrices, imgID)\n",
    "            except Exception as e:\n",
    "                print(\"!!!! WARNING: recognition api call failure in subject matrices creation !!!!\")\n",
    "                print(e)\n",
    "                print(recognitionRes)\n",
    "        imgIDNum += 1\n",
    "    idFile.close()\n",
    "    writeMatrix(picturedWithMatrix, 'takerSubject')\n",
    "    writeMatrix(takerSubjectMatrix, 'picturedWith')\n",
    "    writeStart(0, 'subject')\n",
    "    print('Matrices built!')\n",
    "\n",
    "def randomizeIDs(idString):\n",
    "    idList = idString.split(\",\")\n",
    "    random.shuffle(idList)\n",
    "    idList = [i for i in idList if i]\n",
    "    return ','.join(idList)\n",
    "    \n",
    "def createMonthMatrices():\n",
    "    pictureBySubjectByMonth = getMatrix('pictureBySubjectByMonth')\n",
    "    pictureOfSubjectByMonth = getMatrix('pictureOfSubjectByMonth')\n",
    "    print('Building monthly matrices...')\n",
    "    start = getStart('months')\n",
    "    monthStart, linveStart = [int(i) for i in start.split(\",\")]\n",
    "    for monthNum, monthEntry in enumerate(MONTHS[monthStart:]):\n",
    "        mvvgIDNum, imgID = imgIDNum + lineStart, imgID[:-1] # Cut out the EOL token\n",
    "        (pictureTaker, url) = getPictureTaker(imgID)\n",
    "        if pictureTaker == 'video':\n",
    "             continue\n",
    "        elif pictureTaker == '429':\n",
    "            writeMatrix(pictureBySubjectByMonth, 'pictureBySubjectByMonth')\n",
    "            writeMatrix(pictureOfSubjectByMonth, 'pictureOfSubjectByMonth')\n",
    "            writeStart(str(monthNum)+','+str(imgIDNum), 'months')\n",
    "            return\n",
    "        pictureBySubjectByMonth.at[pictureTaker, monthEntry['name']]+=imgID+','\n",
    "        try:\n",
    "            recognitionRes = recognizeFace(url)\n",
    "            matrices = (None, None, None, pictureOfSubjectByMonth)\n",
    "            processRecognition(recognitionRes, pictureTaker, matrices, imgID, monthEntry['name'])\n",
    "        except Exception as e:\n",
    "            print(\"!!!! WARNING: recognition api call failure in month matrix creation !!!!\")\n",
    "            print(e)\n",
    "            print(recognitionRes)\n",
    "    writeMatrix(pictureBySubjectByMonth, 'pictureBySubjectByMonth')\n",
    "    writeMatrix(pictureOfSubjectByMonth, 'pictureOfSubjectByMonth')\n",
    "    writeStart(str(0)+','+str(0), 'months')\n",
    "    print('Matrices built!')\n",
    "        \n",
    "def createCategoryMatrix():\n",
    "    subjectCategory = getMatrix('subjectCategory')\n",
    "    print('Building category matrix...')\n",
    "    start = getStart('categories')\n",
    "    categoryStart, lineStart = [int(i) for i in start.split(\",\")]\n",
    "    for categoryNum, category in enumerate(CATEGORIES[categoryStart:]):\n",
    "        idFile = open('idFiles/categories/'+category[-1]+'PicIDs.txt', 'r')\n",
    "        categoryNum += categoryStart\n",
    "        ids = idFile.readlines()[lineStart:]\n",
    "        for imgIDNum, imgID in enumerate(ids):\n",
    "            imgIDNum, imgID = imgIDNum + lineStart, imgID[:-1]\n",
    "            (pictureTaker, _) = getPictureTaker(imgID)\n",
    "            if pictureTaker == 'video':\n",
    "                 continue\n",
    "            elif pictureTaker == '429':\n",
    "                writeMatrix(subjectCategory, 'subjectCategory')\n",
    "                writeStart(str(categoryNum)+','+str(imgIDNum), 'categories')\n",
    "                return\n",
    "            subjectCategory.at[pictureTaker, category[-1]]+=imgID+','\n",
    "        idFile.close()\n",
    "    writeMatrix(subjectCategory, 'subjectCategory')\n",
    "    writeStart(str(0)+','+str(0), 'categories')\n",
    "    print('Matrix built!')\n",
    "    \n",
    "\"\"\"\n",
    "    Write the given matrices to csvs with the given names, and write the next run's starting\n",
    "    index to the file with the given startingIndexName.\n",
    "\"\"\"\n",
    "def writeMatrix(matrix, name):\n",
    "    matrix = matrix.applymap(randomizeIDs)\n",
    "    if name == 'takerSubject':\n",
    "        matrix.T.to_csv(\"data/subjectTaker.csv\")\n",
    "    matrix.to_csv(\"data/%s.csv\" %name)\n",
    "\n",
    "def writeStart(start, startingIndexName):\n",
    "    with open('idFiles/startingIndices/%s.txt' %startingIndexName, 'w+') as f:\n",
    "        f.write('%s' %start)\n",
    "    f.close()\n",
    "\n",
    "\"\"\"\n",
    "    Reset the given matrices by writing empty matrices to the csvs with the given names.\n",
    "\"\"\"\n",
    "\n",
    "def resetMatrix(rowLabels, columnLabels, indexName, fileName):\n",
    "    matrix = pd.DataFrame('', index=rowLabels, columns=columnLabels)\n",
    "    matrix.index.name = indexName\n",
    "    matrix.to_csv('data/%s.csv' %fileName)\n",
    "\n",
    "def resetJSON():\n",
    "    writeOverallStatsJSON(emptyOverallStats)\n",
    "\n",
    "def getMatrix(fileName):\n",
    "    matrix = pd.read_csv('data/%s' %fileName)\n",
    "    return matrix\n",
    "              \n",
    "def getOverallStatsJSON():\n",
    "    overallStats = {}\n",
    "    with open('data/overallStats.json') as f_in:\n",
    "        overallStats = json.load(f_in)\n",
    "    f_in.close()\n",
    "    return overallStats\n",
    "\n",
    "def writeOverallStatsJSON(overallStats):\n",
    "    with open(\"data/overallStats.json\", \"w\") as fp:\n",
    "        json.dump(overallStats , fp) \n",
    "    fp.close()\n",
    "                             \n",
    "def getStart(name,matrices):\n",
    "    start = ''\n",
    "    with open('idFiles/startingIndices/%s.txt' %name) as f:\n",
    "        start = f.readlines()[0] \n",
    "    f.close()\n",
    "    return start\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run all our cells to populate the matrices for the frontend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate the subject matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building subject-taker and photographed with matrices...\n",
      "!!!! WARNING: GPRes error while trying to get picture taker\n",
      "{'error': {'code': 401, 'message': 'Request had invalid authentication credentials. Expected OAuth 2 access token, login cookie or other valid authentication credential. See https://developers.google.com/identity/sign-in/web/devconsole-project.', 'status': 'UNAUTHENTICATED'}}\n",
      "Matrices built!\n"
     ]
    }
   ],
   "source": [
    "init_gp_server()\n",
    "\n",
    "statDict = {\n",
    "    'asSubject': 0,\n",
    "    'asPhototaker': 0\n",
    "}\n",
    "\n",
    "emptyOverallStats = {\n",
    "    'chimu':dict(statDict),\n",
    "    'shirleyWhirley': dict(statDict),\n",
    "    'jiusus':dict(statDict),\n",
    "    'me':dict(statDict),\n",
    "    'girlBoss':dict(statDict),\n",
    "    'bugBoy':dict(statDict),\n",
    "    'yuppie':dict(statDict),\n",
    "    'emily':dict(statDict),\n",
    "    'dumbestKid':dict(statDict),\n",
    "    'other': dict(statDict),\n",
    "    'total':0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate the month defined matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading pics with monthly filter...\n",
      "{'error': {'code': 401, 'message': 'Request had invalid authentication credentials. Expected OAuth 2 access token, login cookie or other valid authentication credential. See https://developers.google.com/identity/sign-in/web/devconsole-project.', 'status': 'UNAUTHENTICATED'}}\n",
      "{'error': {'code': 401, 'message': 'Request had invalid authentication credentials. Expected OAuth 2 access token, login cookie or other valid authentication credential. See https://developers.google.com/identity/sign-in/web/devconsole-project.', 'status': 'UNAUTHENTICATED'}}\n",
      "{'error': {'code': 401, 'message': 'Request had invalid authentication credentials. Expected OAuth 2 access token, login cookie or other valid authentication credential. See https://developers.google.com/identity/sign-in/web/devconsole-project.', 'status': 'UNAUTHENTICATED'}}\n",
      "{'error': {'code': 401, 'message': 'Request had invalid authentication credentials. Expected OAuth 2 access token, login cookie or other valid authentication credential. See https://developers.google.com/identity/sign-in/web/devconsole-project.', 'status': 'UNAUTHENTICATED'}}\n",
      "{'error': {'code': 401, 'message': 'Request had invalid authentication credentials. Expected OAuth 2 access token, login cookie or other valid authentication credential. See https://developers.google.com/identity/sign-in/web/devconsole-project.', 'status': 'UNAUTHENTICATED'}}\n",
      "{'error': {'code': 401, 'message': 'Request had invalid authentication credentials. Expected OAuth 2 access token, login cookie or other valid authentication credential. See https://developers.google.com/identity/sign-in/web/devconsole-project.', 'status': 'UNAUTHENTICATED'}}\n",
      "{'error': {'code': 401, 'message': 'Request had invalid authentication credentials. Expected OAuth 2 access token, login cookie or other valid authentication credential. See https://developers.google.com/identity/sign-in/web/devconsole-project.', 'status': 'UNAUTHENTICATED'}}\n",
      "{'error': {'code': 401, 'message': 'Request had invalid authentication credentials. Expected OAuth 2 access token, login cookie or other valid authentication credential. See https://developers.google.com/identity/sign-in/web/devconsole-project.', 'status': 'UNAUTHENTICATED'}}\n",
      "{'error': {'code': 401, 'message': 'Request had invalid authentication credentials. Expected OAuth 2 access token, login cookie or other valid authentication credential. See https://developers.google.com/identity/sign-in/web/devconsole-project.', 'status': 'UNAUTHENTICATED'}}\n",
      "{'error': {'code': 401, 'message': 'Request had invalid authentication credentials. Expected OAuth 2 access token, login cookie or other valid authentication credential. See https://developers.google.com/identity/sign-in/web/devconsole-project.', 'status': 'UNAUTHENTICATED'}}\n",
      "{'error': {'code': 401, 'message': 'Request had invalid authentication credentials. Expected OAuth 2 access token, login cookie or other valid authentication credential. See https://developers.google.com/identity/sign-in/web/devconsole-project.', 'status': 'UNAUTHENTICATED'}}\n",
      "Download complete!\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'data/pictureBySubjectByMonth' does not exist: b'data/pictureBySubjectByMonth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-caa3ddf039ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mresetMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNAMES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmonth\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmonth\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mMONTHS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'client'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'subjectCategory'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_all_month_pics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcreateMonthMatrices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-51-ba338d107e58>\u001b[0m in \u001b[0;36mcreateMonthMatrices\u001b[0;34m()\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreateMonthMatrices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m     \u001b[0mpictureBySubjectByMonth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pictureBySubjectByMonth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m     \u001b[0mpictureOfSubjectByMonth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pictureOfSubjectByMonth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Building monthly matrices...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-51-ba338d107e58>\u001b[0m in \u001b[0;36mgetMatrix\u001b[0;34m(fileName)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m     \u001b[0mmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/%s'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0mfileName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'data/pictureBySubjectByMonth' does not exist: b'data/pictureBySubjectByMonth'"
     ]
    }
   ],
   "source": [
    "init_gp_server()\n",
    "resetMatrix(NAMES, [month['name'] for month in MONTHS], 'client', 'subjectCategory')\n",
    "get_all_month_pics()\n",
    "createMonthMatrices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate the category matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_gp_server()\n",
    "get_all_category_pics()\n",
    "createCategoryMatrix()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_gp_server()\n",
    "### Total pictures \n",
    "try:\n",
    "    res = requests.request(\"GET\", GET_LIBRARIES_URL, headers=PHOTOS_HEADERS)\n",
    "    res.json()\n",
    "    albumID = res.json()['albums'][1]['id']\n",
    "except:\n",
    "    print('!!!! WARNING: Library request error !!!!') \n",
    "    print(res)\n",
    "\n",
    "res = requests.request(\"GET\", GET_LIBRARIES_URL+'/'+albumID, headers=PHOTOS_HEADERS)\n",
    "print(res)\n",
    "res = res.json()\n",
    "totalPictures = int(res['mediaItemsCount'])\n",
    "overallCounts = getOverallCountsJSON()\n",
    "overallCounts['total'] = totalPictures\n",
    "writeOverallStatsJSON(overallCounts)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
